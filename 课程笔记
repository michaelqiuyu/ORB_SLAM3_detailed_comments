一、计算机视觉life课程笔记：
	1. ORB-SLAM3简介
		1.1 ORB-SLAM3量化对比：双目+IMU 》 单目+IMU 》双目

		1.2 数据关联：
			1.2.1 短期数据关联：仅仅和最短几秒内获取的地图元素进行匹配，这是大多数视觉里程计使用的唯一数据关联类型，这种方法存在的问题是：一旦地图元素从视野中消失，就会被丢弃，即使回到原来的地方，也会造成持续的估计漂移。对应ORB-SLAM里的跟踪。
			1.2.2 中期数据关联：匹配距离相机近并且累计漂移较小的地图元素。与短期观测相比，这些信息可以一并加入到BA优化，精度更高的关键所在。对应ORB-SLAM里的局部建图。
			1.2.3 长期数据关联：使用位置识别技术将观测与之前访问过的区域中的元素匹配，不管是在闭环检测中的累计漂移，还是跟踪丢失、重定位的情况下都可以成功匹配。长期匹配允许使用位姿图优化来重置漂移和矫正回环。这是保证中、大型闭环场景中SLAM局部较高精度的关键。对应ORB-SLAM里用词袋进行闭环和重定位。
			1.2.4 多地图数据关联：可以使用之前已经建立的多块地图来实现地图中的匹配和BA优化

		1.3 ORB-SLAM3运行
			1.3.1 在封闭场景，推荐使用ORB系列
			1.3.2 在自动驾驶场景，视觉不会是主要信息来源，视觉不稳定，也基本不会有回环，适合小而美的系统，如VINS系列


	2. ORB-SLAM2回顾
		2.1 有关特征点方向的说明：
			2.1.1 对每一个特征点都可以计算其质心，从而得到方向；从人的角度将，方向始终是没有变化的，但是在不同的视角下，建立的图片坐标系是不同的，因此同一个方向在不同坐标系下得到的方向是不同的，同一个特征点在两个视角下的角度的不同近似表达了两个视角之间的旋转；因此匹配的时候使用角度的一致性检验，保留三个峰值直方图对应的匹配
			2.1.2 注意，一般我们会将两幅图的特征点相连，来观察匹配的正确性，这个时候不用过分关注连线之间是否平行，即使不平行也不能说明匹配是错误的，这是视觉上很容易犯错的，我们还是应该关注匹配的角度差值是否在峰值的直方图中
			2.1.3 在代码中，只有在匹配要求很高或者匹配的不确定性高的时候，才会使用角度一致性检验；
				1. 初始化匹配的时候，要求匹配的正确性非常高，这会显著影响地图的最终精度 
				2. 词袋的匹配的时候，词袋匹配的不确定性较大
				3. 位姿并不准确的投影匹配，如恒速模型得到的位姿、重定位poseoptimize之后内点数量不够（也就是位姿不太准）进行的投影匹配


	3. IMU原理介绍：请参考邱笑晨的IMU笔记《邱笑晨:预积分总结与公式推导20180827》
		3.1 传感器介绍：
			传感器类型          优点               缺点
				轮速			精度高一些	       二维数据
				GPS		  直接输出绝对位置        精度差
				IMU      频率高、短时精度好    无绝对信息、累计误差大


	4. IMU预积分在ORB-SLAM3中的实现：重力始终设置为g(0, 0, -1)，注意正负号
		4.1 IMU初始化：三阶段初始化的函数名（InitializeIMU）都是一样的，只是参数不一样而已
			4.1.1 IMU初始化的目的：获取重力在当前世界系的方向，当然后面是改变世界系的方向，使得重力方向为Z轴负向
				  IMU初始化的参数设置：priorG、priorA、bFirst；前两者为零偏的权重，后者三次初始化的值都一样，用于判断是否进行FullInertialBA

			4.1.2 第一阶段初始化：
				1. 判断条件：惯性模式，但是还没有初始化；单目和非单目的阈值priorA不同（单目1e10，非单目1e5）
				2. 获取距离第一个关键帧一定的时间且地图中有一定数量的关键帧
				3. 根据Ri * △Vij = Vj - Vi - g * △tij，注意这里的世界系的Z轴为g的负向，与当前视觉的世界系不一样。
					3.1 首先将世界系修改为当前视觉的世界系，也就是Ri' * △Vij = sVj' - sVi' - Rwg * g * △tij，其中Vi和Vj根据视觉进行计算
					3.2 mOwb1 = Rwc1 * tcb + stwc1, mOwb2 = Rwc2 * tcb + stwc2, 从而mOwb2 - mOwb1 = Rwc2 * tcb - Rwc1 * tcb + stwc2 - stwc1，在这里认为Rwc1和Rwc2近似相等（连续两个关键帧的旋转确实比较接近，而且后面还会做尺度和重力的refine），因此有mOwb2 - mOwb1 = s(twc2 - twc1)，否则mOwb2 - mOwb1的结果的尺度是模糊的，也就是一部分有尺度，一部分没有尺度。据此计算速度
					3.3 令i = j - 1，对j进行递增求和，得到dirG = Rwg * g * sum_t - sVn，忽略sVn，就形成了y = Rx计算R的形式，据此计算Rwg的初始值：通过x和y计算旋转轴，然后计算旋转角，然后计算轴角，得到旋转矩阵
					3.4 此处忽略Vn的影响导致求得的R必然是不准确的，而且这种不准确与Vn的大小密切相关；仅能作为初值用于后面对R的精确化求解
					3.5 s是一个待求的常数，Vn是速度，不是一个剧烈波动的数，因此sVn是一个稳定的数值，时间越长，n*Rwg*g*t在dirG中所占的比重越大，近似的准确性也就越高，因此，对have_imu_num以及关键帧数量和时间有要求
					3.6 计算mTinit = 当前关键帧的时间戳 - 第一个没有prev关键帧的关键帧的时间戳
					3.6 第一阶段初始化成功后，后续进入到InitializeIMU函数，Rwg的初始值为单位阵，零偏使用之前优化的结果
				4. 不利用速度或者位移来计算Rwg的原因，以下以速度来做说明：
					4.1 根据相机位姿计算速度V1，如Eigen::Vector3f _vel = ((*itKF)->GetImuPosition() - (*itKF)->mPrevKF->GetImuPosition())/(*itKF)->mpImuPreintegrated->dT;
                    4.2 根据IMU预积分递推得到对应时刻的速度V2
                    4.3 那么上面两个速度分别是在世界系W和g下获得的，据此可以得到Rwg
                    4.4 V2实际上不可求，因为IMU递推的初值旋转不可知，因为IMU递推默认世界系g的Z轴为重力反向，因此初始旋转并不是单位阵
                    4.5 因此，此处使用相同方法的位姿，也无法获取Rwg
				5. InertialOptimization优化：
					5.1 构建的边有8个顶点，其中VP1、VV1、VP2、VV2是时变的，VG、VA、VGDir、VS是时不变的（也就是只建立一个顶点）
					5.2 注意这里的预积分项与邱笑晨文档的预积分项是不同的，因此求解的雅克比也是不同的（变化很小）
					5.3 对重力的处理：由于一直重力方向g=(0, 0, -1)，因此Rwg对应的轴角的形式为(a, b, 0)，为2自由度
					5.4 一定要明确预积分量与世界系的选择无关，相关推导见代码和邱笑晨文档，这也是能够这样进行预积分初始化的原因
					5.5 关于尺度的更新预计定义不同，应该是一个bug
					5.6 由于priorA的不同，LM算法的lambda也不同
					5.7 优化结束后，设置关键帧的零偏、速度；注意，位姿是不更新的
				6. ApplyScaledRotation：单目视觉基于一个未知尺度构建，得到尺度s后，应用s；变换世界系
					6.1 变换世界系，将世界系变换为重力方向为Z轴负向
					6.2 更新每一帧的位姿：平移的尺度，世界系变化导致的位姿变化，每一帧速度的尺度和坐标系变化
					6.3 地图点的尺度和世界系变化引起的变化
				7. UpdateFrameIMU
					7.1 更新mlRelativeFramePoses的尺度，Frame的位姿由此计算
					7.2 更新mLastBias，并设置mpLastKeyFrame，更新上一帧和当前帧的零偏
					7.3 更新上一帧的SetImuPoseVelocity：速度、依据Tbw计算的Tcw，相机光心等
					7.4 更新当前帧的SetImuPoseVelocity：速度、依据Tbw计算的Tcw，相机光心等
					7.5 mnFirstImuFrameId = mCurrentFrame.mnId;
					7.6 实际上，一般不直接使用Frame的位姿，一般都是基于其参考关键帧来计算位姿，这里计算得到的位姿，不一定使用了
				8. 对每一帧关键帧，标记bImu = true；注意，此步骤只在第一阶段初始化中有
				9. 设置地图初始化成功，以及相关变量
				10. 视觉惯性联合优化；bFirst为true，执行Optimizer::FullInertialBA(mpAtlas->GetCurrentMap(), 100, false, mpCurrentKeyFrame->mnId, NULL, true, priorG, priorA);注意第三阶段的参数不同
					10.1 第一、第二阶段只会建立一个零偏顶点，第三阶段会根据每一个关键帧建立一个零偏的顶点
					10.2 第一、第二阶段对零偏的约束是一元边，将零偏约束在0附近；第三阶段是二元边，也就是前后两帧两帧的零偏需要接近
					10.3 添加视觉边，区分左右目和双目，双目情况下，都是重投影误差，边的数量会多于左右目
					10.4 保存优化后的结果，为后面更新做准备
				11. 处理新进来的关键帧
				12. 从地图的初始关键帧开始，更新关键帧的位姿、速度、零偏；使用了扩展树，计算过程使用了是否参与了10的优化
				13. 对地图的所有地图点进行更新，计算过程使用了是否参与了10的优化，基于参考关键帧进行更新

			4.1.3 第二阶段初始化：mTinit小于100s，并且处于惯性模式
				1. 判断条件：第一阶段初始化成功，跟踪正常，还没有进行VIBA1，mTinit大于5s；单目非单目的阈值一致（但是使用了if语句进行判断）
				2. 设定Rwg的初始值为单位阵，零偏使用之前优化的结果
				3. 执行第一阶段初始化的步骤5~7、9~13
				4. 经历一定的时间（mTinit大于5s）再执行，此时时间还不是很久，可以只使用一个零偏

			4.1.4 第三阶段初始化：mTinit小于100s，并且处于惯性模式
				1. 判断条件：第一阶段初始化成功，跟踪正常，还没有进行VIBA2，mTinit大于15s；单目非单目的阈值一致（但是使用了if语句进行判断）
				2. Rwg的初始值为单位阵，零偏使用之前优化的结果
				3. 执行第一阶段初始化的步骤5~7、9~13
				4. 经历一定的时间（mTinit大于15s）再执行，此时时间已经比较久了，不再适合只使用一个零偏了


		4.2 尺度重力方向优化：距离IMU第一阶段初始化成功累计时间小于100s，并且处于惯性模式，累计关键帧数量不超过200帧
			4.2.1 距离IMU第一阶段初始化成功累计时间在25~25.5、35~35.5、45~45.5、55~55.5、65~65.5、75~75.5；并且是单目的时候执行
			4.2.2 ScaleRefinement
				1. 设置Rwg为单位阵，尺度为1，执行InertialOptimization，优化重力和尺度
				2. InertialOptimization
					2.1 构建的边有8个顶点，其中VP1、VV1、VP2、VV2、VG、VA固定不变，VGDir、VS为优化的状态量
					2.2 获得优化结果
				3. 执行ApplyScaledRotation，与上面相同
				4. 执行UpdateFrameIMU，与上面相同
				5. 优化的这段时间进来的关键帧，全部删除不要，清空mlNewKeyFrames

	5. 跟踪线程
		5.1 如果局部建图线程认为IMU有问题，就ResetActiveMap：重置当前活跃地图，不保存当前地图

		5.2 mState != NO_IMAGES_YET
			5.2.1 如果上一帧的时间戳大于当前帧的时间戳，那么就CreateMapInAtlas（保存当前地图，并创建一个新地图）
			5.2.2 如果当前帧的时间戳>上一帧时间戳+1，那么仅处理惯性模式
				1. 如果已经经过了第一阶段初始化
					1.1 固脱没有完成第三阶段初始化，那么ResetActiveMap
					1.2 否则，保存当前地图，并创建一个新地图CreateMapInAtlas
				2. 否则，直接ResetActiveMap

		5.3 如果是IMU模式下，就将上一关键帧的零偏赋值为当前帧

		5.4 如果没有图像，就将状态mState设置为NOT_INITIALIZED

		5.5 在IMU模式下，并且mbCreatedMap=False的时候，进行IMU预积分
			5.5.1 对mbCreatedMap的阐述：
				1. 创建地图的时候CreateMapInAtlas，mbCreatedMap=True，这个含义应该是刚刚创建地图，还没有图片信息，自然不需要预积分
				2. 一旦有图片进来后，mbCreatedMap=false，这个时候就需要预积分了
			5.5.2 PreintegrateIMU
				1. 通过插值计算两帧之间的IMU测量值信息
				2. 对上一帧执行IMU预积分计算，对上一关键帧执行预积分计算，注意pImuPreintegratedFromLastFrame为新建的局部变量，mpImuPreintegratedFromLastKF为Track的成员变量，并对当前帧的mpImuPreintegratedFrame、mpImuPreintegrated和mpLastKeyFrame进行赋值
				3. 设置当前帧的预积分结束

		5.6 初始化
			5.6.1 单目初始化MonocularInitialization
				1. mbReadyToInitializate为false
					1.1 如果当前帧的特征点的数目>100，设置相关变量，如给mpImuPreintegratedFromLastKF、mCurrentFrame.mpImuPreintegrated赋值，并设置mbReadyToInitializate为true
				2. 否则（第二帧来了）
					2.1 条件1：特征点的数目<100；条件二：IMU模式，上一帧时间戳-初始帧时间戳>1；条件1/2只要满足其一，那么mbReadyToInitializate设置为false，并直接结束
					2.2 两帧之间构建匹配，匹配的方法是窗口匹配（认为两帧比较接近，直接画圈搜索），匹配数量<100，那么mbReadyToInitializate设置为false，并直接结束；否则，执行2.3
					2.3 两帧重建：ReconstructWithTwoViews
						2.3.1 相机模型
							1. 针孔相机：执行Reconstruct
							2. 鱼眼相机：对特征点去畸变、执行Reconstruct；注意，鱼眼相机仅仅在初始化阶段执行去畸变，其他时候都是带着畸变进行处理
						2.3.2 Reconstruct
							1. 迭代创建最小集（8点法）
							2. 多线程计算F和H，并计算得分，据此获得最优的几何模型
							3. 从F或者H中分解出R和t
					2.4 两帧重建成功，就执行CreateInitialMapMonocular
						2.4.1 设置地图最开始的两个关键帧，如果是IMU模式，就设置第一个关键帧的mpImuPreintegrated为NULL
						2.4.2 对两个关键帧计算词袋、插入地图、设置地图点
						2.4.3 更新两帧之间的连接UpdateConnections，并设置尺度，并据此尺度，修改地图点和位姿
						2.4.4 其他的一些必要操作，并设置mState为OK

			5.6.2 双目/RGBD初始化StereoInitialization
				1. 特征点的数目>500，否则，直接结束
				2. 如果是IMU模式
					1. 如果当前帧或者前一帧的mpImuPreintegrated为NULL，那么直接结束，也就是第一和第二帧不执行初始化
					2. 如果非快速IMU初始化，并且当前帧的预积分的平均加速度-上一帧的预积分的平均加速度的模长<0.5，表示没有足够的加速度，直接结束
					3. 如果mpImuPreintegratedFromLastKF不为NULL，就delete并重新new，并将其赋值给当前帧的mpImuPreintegrated
				3. 如果是IMU模式，就是值当前帧的R、t、v，注意世界系为相机系，设置的是IMU的信息；否则，直接设置当前帧的位姿为单位阵
				4. 设置当前帧为第一个关键帧，并将其添加到地图中
				5. 如果是双目模式：对深度值为正的特征点，取出mvDepth中的值并构建地图点，并添加到地图中
				6. 如果是左右目模式：取出mvStereo3Dpoints中的地图点，并构建地图点，并添加到地图中，注意，这里一个地图点在mvpMapPoints存储了两次，但是下标是不同的
				7. 其他的一些必要的操作，并设置mState为OK

			5.6.3 如果初始化失败，就将上一帧设置为当前帧，并直接结束；否则，如果当前地图是Atlas地图中的第一个子地图，那么就设置mnFirstFrameId为当前帧的mnId

		5.7 跟踪模式
			5.7.1 正常的SLAM模式
				1. mstate == OK:
					1.1 CheckReplacedInLastFram:检查上一帧中是否有点需要地图点在局部建图线程中被替换，如果发生替换，就将上一帧的地图点也对应替换，注意，这也是局部建图线程没有直接删除这些被替换的地图点的原因，如果在局部建图线程中被删除，那么上一帧中需要被替换的地图点也就被删除了，也就没办法执行替换操作了
					1.2 条件1：没有速度且没有imu初始化；条件2：刚刚重定位成功；如果条件1或者条件2满足，那么就执行参考关键帧跟踪TrackReferenceKeyFrame：
						1.2.1 TrackReferenceKeyFrame:
							1. 
					1.3 如果条件1和条件2都不满足，那么执行恒速模型跟踪TrackWithMotionModel，如果恒速模型跟踪失败，那么执行TrackReferenceKeyFrame
						1.3.1 TrackWithMotionModel：
							1. 
					1.4 如果上面的跟踪都失败：
						1.4.1 条件1：IMU模式；条件2：当前帧的ID<=上一次重定位成功的帧的ID+mnFramesToResetIMU（一般与相机帧率相同），也就是表示重定位成功没过多久就又失败了；条件1和条件2都满足的时候，就mState=LOST，认为跟丢了。否则，执行1.4.2 
						1.4.2 当前地图中的关键帧数目超过10帧，执行mState=RECENTLY_LOST，也就是会利用其他信息继续跟踪，不认为跟丢了。并记录此时的时间戳信息mTimeStampLost，否则，执行1.4.3 
						1.4.3 mstate=lost，认为跟丢了
				2. mstate != OK:
					2.1 mstate=recently_lost:
						2.1.1 先设置bOK=true
						2.1.2 如果是IMU模式，否则执行2.1.3：
							1. 如果当前地图已经MU初始化，那么就执行PredictStateIMU：
								1.1 
							2. 否则，令bOK=false
							3. 如果当前帧的时间戳减去跟丢的时间戳mTimeStampLost的值大于time_recently_lost（5s），那么，mstate=lost，也就是尝试重建跟踪失败了，并且令bOK=false
						2.1.3 非IMU模式：
							1. bOK=Relocalization:
								1.1 
							2. 如果重定位失败，并且当前帧的时间戳-跟丢的时间戳mTimeStampLost的值大于3s，那么认为跟丢了，mstate=lost，bOK=false
					2.2 mstate=lost:
						2.2.1 如果当前地图中的关键帧数目少于10帧，那么ResetActiveMap，也就是对这少量的几个关键帧不保存，否则
						2.2.2 CreateMapInAtlas，保存当前地图，并新建一个新地图
						2.2.3 将mpLastKeyFrame赋空

			5.7.2 仅定位模式：此模式不运行局部建图线程和回环线程
				1. 











git: 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

后续重点查看一下：4自由度的本质图优化

零偏的初始值是0，之后帧的初值可以根据上一帧或者上一关键帧

Tracking::PreintegrateIMU


// 总结下都在什么时候地图更新，也就是mbMapUpdated为true
// 1. 回环或融合
// 2. 局部地图LocalBundleAdjustment
// 3. IMU三阶段的初始化


左右目的形式的相机类型为：Rectified，对应的数据集为KITTI


// 这里关注一下
// 1. 对于行列数一样的矩阵，Eigen::ComputeThinU | Eigen::ComputeThinV    与    Eigen::ComputeFullU | Eigen::ComputeFullV 一样
// 2. 对于行列数不同的矩阵，例如3*4 或者 4*3 矩阵只有3个奇异向量，计算的时候如果是Thin 那么得出的UV矩阵列数只能是3，如果是full那么就是4
// 3. thin会损失一部分数据，但是会加快计算，对于大型矩阵解算方程时，可以用thin加速得到结果



目前尚未明白的点：
	1. 计算avgW、avgA的目的是什么？
	2. 两个普通帧之间的IMU预积分是比较准的，应该时间间隔比较小；如果是两个关键帧之间的话，时间间隔比较长，还是直接使用IMU预积分来构建约束吗？
	3. point-pose约束构架的hessian是稀疏的，但是添加了IMU信息或者光心约束之后还是稀疏的吗？还能使用稀疏求解器吗？
	4. 在邱笑晨的文档中，并没有将零偏当做状态量进行状态递推，那么代码里面实现的时候是如何构建他们之间的协方差的？
	5. 由于更新的并不是零偏，而是零偏的增量，因此零偏是如何更新的，零偏更新后，是否使用一阶泰勒进行展开求解预积分的更新量，当然此时的零偏也已经同步更新了
	6. 单目+imu模式下可以较快的初始化地图，速度大于ORB2的单目初始化？速度提升来自于哪里？
	7. 当零偏更新之后，预计分量会根据一阶泰勒公式进行更新，对各状态量的导数（实际上应该根据零偏的变化同步更新）却没有同步更新（初始化的时候有可能重新预积分，之后就不会重新预积分了，认为零偏的波动很小）


代码尚存疑惑点：
	1. 在恒速模型中UpdateLastFrame函数中，仅仅在非SLAM模式的多目下生成临时地图点用于增强跟踪，在SLAM系统下不生成；


notes：
	1. 多目使用方式，在跟踪中并没有起到作用，仅仅在BA中产生作用
	2. 在跟踪线程判定为关键帧的时候，如果是多目，会根据多目创建的地图点添加到关键帧之中


	




1. 学习ORB-SLAM3中多相机的使用
	1.1 在构造Frame的时候：双目模式会做深度计算；非双目模式会做三角化获得在左相机的深度
	1.2 跟踪过程会根据立体视觉恢复出部分点，增强跟踪的稳定性（代码中只有在非SLAM模式下，才会执行，不太合理）
	1.3 在当前帧被判定为关键帧的时候，会添加双目重建出来但是没有跟踪到的地图点到地图中，并给其添加相应属性信息，从而利用了多目信息
	1.4 优化的过程中
		1.3.1 如果是纯视觉，使用uv = π(Trl * Tlw * Pw)，其中Trl为两个相机外参，优化过程中不变，优化变量为Tlw和Pw
		1.3.2 如果是VIO，优化的变量是Tbw，然后根据Tcb去计算每个相机的位姿，优化过程中不会优化Tcb和两个相机之间的外参Trl
		1.3.3 无论是纯视觉还是VIO，实际上都是构建一个枢纽帧。在纯视觉中，枢纽帧是左相机系；在VIO中，枢纽帧是IMU的body系；优化仅仅优化枢纽帧的位姿，不会优化枢纽帧与其他各帧之间的相对位姿




运行实例：
	1. 双目（非左右目）：
		./Examples/Stereo/stereo_euroc ./Vocabulary/ORBvoc.txt ./Examples/Stereo/EuRoC.yaml /home/xiongchao/studying/SLAM/VSLAM/ORB-SLAM/orb3/dataset/MH_01_easy ./Examples/Stereo/EuRoC_TimeStamps/MH01.txt dataset-MH01_stereo

	2. 双目（非左右目）+IMU：
		./Examples/Stereo-Inertial/stereo_inertial_euroc ./Vocabulary/ORBvoc.txt ./Examples/Stereo-Inertial/EuRoC.yaml /home/xiongchao/studying/SLAM/VSLAM/ORB-SLAM/orb3/dataset/MH_01_easy ./Examples/Stereo/EuRoC_TimeStamps/MH01.txt

		./Examples/Stereo-Inertial/stereo_inertial_tum_vi ./Vocabulary/ORBvoc.txt ./Examples/Stereo-Inertial/EuRoC.yaml /home/xiongchao/studying/SLAM/VSLAM/ORB-SLAM/orb3/dataset/MH_01_easy/mav0/cam0/data /home/xiongchao/studying/SLAM/VSLAM/ORB-SLAM/orb3/dataset/MH_01_easy/mav0/cam1/data ./Examples/Stereo-Inertial/EuRoC_TimeStamps/MH01.txt ./Examples/Stereo-Inertial/EuRoC_IMU/MH01.txt dataset-corridor1_512_stereoi